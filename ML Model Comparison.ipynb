{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On the date this code was written (04/15/2020), the following future warning appeared:\n",
    "#C:\\Users\\Angela Scarano\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
    "#  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
    "\n",
    "#Therefore, my default parameters for the homework and report are likely operating with n_estimators = 10, not 100,\n",
    "#incase that changes anything\n",
    "\n",
    "#I coded the homework before I realized there was attribute information given on the website where the data was retrieved.\n",
    "#The report has a chart notating which feature belongs to which attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8484736809778269\n"
     ]
    }
   ],
   "source": [
    "#This is the base code used for the Random Forest Classifier\n",
    "#all 14 features present and completely default Random Forest Classifier parameters\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#divide data into features and target labels for both training and testing data\n",
    "col_list_1 = [\"Feat 1\", \"Feat 2\", \"Feat 3\", \"Feat 4\", \"Feat 5\", \"Feat 6\", \"Feat 7\", \"Feat 8\", \"Feat 9\", \"Feat 10\", \"Feat 11\", \"Feat 12\", \"Feat 13\", \"Feat 14\"]\n",
    "col_list_2 = [\"Target\"]\n",
    "\n",
    "train_features = pd.read_csv(\"adultdata.csv\", usecols=col_list_1)\n",
    "train_targets = pd.read_csv(\"adultdata.csv\", usecols=col_list_2)\n",
    "\n",
    "test_features = pd.read_csv(\"adulttest.csv\", usecols=col_list_1)\n",
    "test_targets = pd.read_csv(\"adulttest.csv\", usecols=col_list_2)\n",
    "\n",
    "#convert non-numerical features into numerical versions for sklearn Random Forest\n",
    "train_features = train_features.apply(LabelEncoder().fit_transform)\n",
    "train_targets = train_targets.apply(LabelEncoder().fit_transform)\n",
    "test_features = test_features.apply(LabelEncoder().fit_transform)\n",
    "test_targets = test_targets.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#These were used to visually test that data was divided correctly\n",
    "#train_targets.head()\n",
    "#train_features.head()\n",
    "#test_features.head()\n",
    "#test_targets.head()\n",
    "\n",
    "#train Random Forest with training data and default Random Forest Classifier settings\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_features, np.ravel(train_targets))\n",
    "\n",
    "#obtain predictions and accuracy of predictions with test data\n",
    "predictions = rfc.predict(test_features)\n",
    "base_accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", base_accuracy)\n",
    "\n",
    "#Used to obtain feature importance data\n",
    "#print(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.856704133652724\n",
      "Change:  -0.00012284257723726988\n"
     ]
    }
   ],
   "source": [
    "#This is the code used for alternate states of the Random Forest Classifier homework\n",
    "#Features and Random Forest Classifier parameters altered as needed for assignment\n",
    "#Not all changes are saved, this is just a space to make those changes while maintaining a working copy of code above\n",
    "#This code may be different or missing some features / adding some parameters when compared to the code above, due to the\n",
    "#HW questions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#divide data into features and target labels for both training and testing data\n",
    "#This is where I remove features when asked to do so by the HW. I just remove the appropriate feature from the column list\n",
    "col_list_1 = [\"Feat 1\", \"Feat 2\", \"Feat 3\", \"Feat 4\", \"Feat 5\", \"Feat 6\", \"Feat 7\", \"Feat 8\", \"Feat 9\", \"Feat 10\", \"Feat 11\", \"Feat 12\", \"Feat 13\"]\n",
    "col_list_2 = [\"Target\"]\n",
    "\n",
    "train_features = pd.read_csv(\"adultdata.csv\", usecols=col_list_1)\n",
    "train_targets = pd.read_csv(\"adultdata.csv\", usecols=col_list_2)\n",
    "\n",
    "test_features = pd.read_csv(\"adulttest.csv\", usecols=col_list_1)\n",
    "test_targets = pd.read_csv(\"adulttest.csv\", usecols=col_list_2)\n",
    "\n",
    "#convert non-numerical features into numerical versions for sklearn Random Forest\n",
    "train_features = train_features.apply(LabelEncoder().fit_transform)\n",
    "train_targets = train_targets.apply(LabelEncoder().fit_transform)\n",
    "test_features = test_features.apply(LabelEncoder().fit_transform)\n",
    "test_targets = test_targets.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#These were used to visually test that data was divided correctly\n",
    "#train_targets.head()\n",
    "#train_features.head()\n",
    "#test_features.head()\n",
    "#test_targets.head()\n",
    "\n",
    "#train Random Forest with training data and default Random Forest Classifier settings\n",
    "#This is where I alter Random Forest Classifier parameters as needed for the HW\n",
    "rfc = RandomForestClassifier(max_depth = 20, n_estimators = 400)\n",
    "rfc.fit(train_features, np.ravel(train_targets))\n",
    "\n",
    "#obtain predictions and accuracy of predictions with test data\n",
    "predictions = rfc.predict(test_features)\n",
    "base_accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", base_accuracy)\n",
    "print(\"Change: \", base_accuracy - 0.8568269762299613)\n",
    "\n",
    "#Used to obtain feature importance data\n",
    "#print(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.801486395184571\n"
     ]
    }
   ],
   "source": [
    "#This is the base code used for the K Nearest Neighbors Classifier\n",
    "#all 14 features present, parameters may be altered from default\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#divide data into features and target labels for both training and testing data\n",
    "col_list_1 = [\"Feat 1\", \"Feat 2\", \"Feat 3\", \"Feat 4\", \"Feat 5\", \"Feat 6\", \"Feat 7\", \"Feat 8\", \"Feat 9\", \"Feat 10\", \"Feat 11\", \"Feat 12\", \"Feat 13\", \"Feat 14\"]\n",
    "col_list_2 = [\"Target\"]\n",
    "\n",
    "train_features = pd.read_csv(\"adultdata.csv\", usecols=col_list_1)\n",
    "train_targets = pd.read_csv(\"adultdata.csv\", usecols=col_list_2)\n",
    "\n",
    "test_features = pd.read_csv(\"adulttest.csv\", usecols=col_list_1)\n",
    "test_targets = pd.read_csv(\"adulttest.csv\", usecols=col_list_2)\n",
    "\n",
    "#convert non-numerical features into numerical versions for sklearn Random Forest\n",
    "train_features = train_features.apply(LabelEncoder().fit_transform)\n",
    "train_targets = train_targets.apply(LabelEncoder().fit_transform)\n",
    "test_features = test_features.apply(LabelEncoder().fit_transform)\n",
    "test_targets = test_targets.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#These were used to visually test that data was divided correctly\n",
    "#train_targets.head()\n",
    "#train_features.head()\n",
    "#test_features.head()\n",
    "#test_targets.head()\n",
    "\n",
    "#train with training data\n",
    "knn = KNeighborsClassifier(n_neighbors=20, p=1)\n",
    "knn.fit(train_features, np.ravel(train_targets))\n",
    "\n",
    "#obtain predictions and accuracy of predictions with test data\n",
    "predictions = knn.predict(test_features)\n",
    "base_accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.821018364965297\n"
     ]
    }
   ],
   "source": [
    "#This is the base code used for the Gaussian Naive Bayes Classifier\n",
    "#all 14 features present, parameters may be altered from default\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#divide data into features and target labels for both training and testing data\n",
    "col_list_1 = [\"Feat 1\", \"Feat 2\", \"Feat 3\", \"Feat 4\", \"Feat 5\", \"Feat 6\", \"Feat 7\", \"Feat 8\", \"Feat 9\", \"Feat 10\", \"Feat 11\", \"Feat 12\", \"Feat 13\", \"Feat 14\"]\n",
    "col_list_2 = [\"Target\"]\n",
    "\n",
    "train_features = pd.read_csv(\"adultdata.csv\", usecols=col_list_1)\n",
    "train_targets = pd.read_csv(\"adultdata.csv\", usecols=col_list_2)\n",
    "\n",
    "test_features = pd.read_csv(\"adulttest.csv\", usecols=col_list_1)\n",
    "test_targets = pd.read_csv(\"adulttest.csv\", usecols=col_list_2)\n",
    "\n",
    "#convert non-numerical features into numerical versions for sklearn Random Forest\n",
    "train_features = train_features.apply(LabelEncoder().fit_transform)\n",
    "train_targets = train_targets.apply(LabelEncoder().fit_transform)\n",
    "test_features = test_features.apply(LabelEncoder().fit_transform)\n",
    "test_targets = test_targets.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#These were used to visually test that data was divided correctly\n",
    "#train_targets.head()\n",
    "#train_features.head()\n",
    "#test_features.head()\n",
    "#test_targets.head()\n",
    "\n",
    "#train with training data\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_features, np.ravel(train_targets))\n",
    "\n",
    "#obtain predictions and accuracy of predictions with test data\n",
    "predictions = gnb.predict(test_features)\n",
    "base_accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8206498372335852\n"
     ]
    }
   ],
   "source": [
    "#This is the base code used for the Linear Discriminant Analysis Classifier\n",
    "#all 14 features present, parameters may be altered from default\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "#divide data into features and target labels for both training and testing data\n",
    "col_list_1 = [\"Feat 1\", \"Feat 2\", \"Feat 3\", \"Feat 4\", \"Feat 5\", \"Feat 6\", \"Feat 7\", \"Feat 8\", \"Feat 9\", \"Feat 10\", \"Feat 11\", \"Feat 12\", \"Feat 13\", \"Feat 14\"]\n",
    "col_list_2 = [\"Target\"]\n",
    "\n",
    "train_features = pd.read_csv(\"adultdata.csv\", usecols=col_list_1)\n",
    "train_targets = pd.read_csv(\"adultdata.csv\", usecols=col_list_2)\n",
    "\n",
    "test_features = pd.read_csv(\"adulttest.csv\", usecols=col_list_1)\n",
    "test_targets = pd.read_csv(\"adulttest.csv\", usecols=col_list_2)\n",
    "\n",
    "#convert non-numerical features into numerical versions for sklearn Random Forest\n",
    "train_features = train_features.apply(LabelEncoder().fit_transform)\n",
    "train_targets = train_targets.apply(LabelEncoder().fit_transform)\n",
    "test_features = test_features.apply(LabelEncoder().fit_transform)\n",
    "test_targets = test_targets.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "#These were used to visually test that data was divided correctly\n",
    "#train_targets.head()\n",
    "#train_features.head()\n",
    "#test_features.head()\n",
    "#test_targets.head()\n",
    "\n",
    "#train with training data\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train_features, np.ravel(train_targets))\n",
    "\n",
    "#obtain predictions and accuracy of predictions with test data\n",
    "predictions = lda.predict(test_features)\n",
    "base_accuracy = metrics.accuracy_score(test_targets, predictions)\n",
    "print(\"Accuracy: \", base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
